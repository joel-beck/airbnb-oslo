\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{parskip}

\usepackage{graphicx}
\graphicspath{{../images/}}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=blue,
    citecolor=blue,
    filecolor=blue,
}
\urlstyle{same}

\title{Paper Structure}
\author{}
\date{}


\begin{document}

\maketitle
\tableofcontents
\setcounter{tocdepth}{3}

\section{Introduction}

\section{Methods}

\subsection{Preprocessing}

\subsubsection{Feature Engineering}

\textbf{Images}

\textbf{Reviews}
%%%
\begin{itemize}
    \item Description of Sentiment Analysis, stating procedure and results and including \textbf{Figure} with Wordcloud, either only English Words or Side-by-Side Wordclouds of English and Norwegian Words
    \item In addition: Language Detection to include the \emph{number of different languages} and the \emph{fraction of norwegian languages} and Analyzing the reviews lengths to include the \emph{median review length}
    \item Since there are multiple reviews per apartment the results for each review were averaged for each apartment separately.
\end{itemize}
%%%

\textbf{Others}
%%%
\begin{itemize}
    \item Optionally mention all other features that we added to the dataset
\end{itemize}
%%%


\subsubsection{Manual Feature Selection}
%%%
\begin{itemize}
    \item Describe process of combining features from images, reviews and numeric features into one dataframe
    \item Decision to select features for the final model were based on:
          \begin{itemize}
              \item Human Background/Context Knowledge (Apartment \emph{Size} is a sensible predictor for the price by intuition)
              \item marginal relationships to price detected by visualization (barplot for categorical variable vs. price or scatterplot for numeric variable vs. price)
              \item Small Dataset with around $3000$ observations: If no reasonable imputation is possible, consider tradeoff between additional predictive value of a variable and number of lost data points due to missing values
              \item Final Step: Built Linear Regression Model with (almost) all features and investigate features with high coefficients in absolute value.
                    Since variables are standardized, coefficient magnitudes have meaning.
          \end{itemize}
\end{itemize}
%%%


\subsubsection{Encoding and Automatic Feature Selection}
%%%
\begin{itemize}
    \item One-Hot Encoding of Categorical Variables, Standardization of Numeric Variables
    \item Experimenting with different ways of algorithm-based feature selection / dimensionality reduction
    \item Focus on \texttt{PCA} as most theoretically supported procedure and \texttt{RFE} as procedure we chose
    \item PCA has advantage of reducing dimensionality and simultaneously producing \emph{uncorrelated} features, disadvantage of producing linear combinations of original features which are harder to interpret
    \item \texttt{RFE} showed best performance and selects subset of original features, can be immediately interpreted as potentially most important features
    \item Briefly explain how \texttt{RFE} works
\end{itemize}
%%%


\subsection{Models}

\subsubsection{Classical Models}
%%%
\begin{itemize}
    \item serve as benchmark models to better evaluate performance of custom neural network
    \item selected with increasing degrees of complexity and corresponding decreasing degree of interpretability
    \item Focus on $4$ models: \texttt{LinearRegression}, \texttt{Ridge}, \texttt{RandomForest} and \texttt{HistGradientBoosting}
    \item Describe Model Fitting process and hyperparameter tuning with Randomized Search Cross Validation
\end{itemize}
%%%

\subsubsection{Neural Network}


\subsubsection{Price Distribution}
%%%
\begin{itemize}
    \item \textbf{Figure} of Side-by-Side Histograms of Price and Log-Price Distribution
    \item Price Distribution right-skewed with some very large outliers
    \item Explain benefits of normally distributed dependent variable, particular for models with distributional assumptions (e.g. Linear Regression vs. Neural Network)
    \item State that all classical Machine Learning Models benefitted from log transformation
    \item Briefly discuss why we did not transform the price variable for the Neural Network
\end{itemize}
%%%


\section{Results}

\subsection{Predictive Performance}
%%%
\begin{itemize}
    \item \textbf{Figure} of performance comparison between selected classical models and neural network for given feature selector (e.g. RFE) and different number of selected features
    \item Interpret Differences in Training and Validation Performance between different models
    \item Interpret Differences in Performance for different number of selected features
    \item Compare Performance on Validation Set with Performance on Test Set for the best model of each class by means of a table \\
          $\Rightarrow$ Models whose hyperparameters were tuned on validation set generalize worse to test set, e.g. \texttt{HistGradientBoosting}, \texttt{RandomForest} and \texttt{Ridge}
    \item Include average predictions of top 2/3/4/5 models, where models are selected based on validation set performance and Test Set predictions are averaged
    \item Potentially mention which models contributed to predictions on new, unseen dataset from challenge
\end{itemize}
%%%

\subsection{Explainability / Interpretability}

\subsubsection{Feature Importance}
%%%
\begin{itemize}
    \item \textbf{Figure} of Coefficient Plot for Linear Regression with e.g. $25$ selected features
    \item Interpret Figure
\end{itemize}
%%%

\subsubsection{Sensitivity of Neural Network Performance on Outliers}
%%%
\begin{itemize}
    \item State shortcomings of Neural Net to predict prices in the tails of the distribution, error metrics thus largely impacted by outliers
    \item State (maybe with a table) drastic increase in predictive performance when excluding largest quantiles of price distribution from dataset
    \item Discuss if the task itself is theoretically feasible for any kind of model
    \item \textbf{Figure} of latent space representation
    \item Discuss that the data is not expressive enough to capture all features that determine the price in reality, particularly for apartments with very high prices, that do not differ from lower priced apartments based on their feature set
    \item Question underlying assumptions that all apartments are reasonably priced, difficult to detect overpriced listings that bias model predictions
\end{itemize}
%%%


\section{Conclusion}


% ask for order of appendix and references
\section{Appendix}
%%%
\begin{itemize}
    \item include link to repository with codebase to reproduce all findings
\end{itemize}
%%%

\section{References}

\end{document}
