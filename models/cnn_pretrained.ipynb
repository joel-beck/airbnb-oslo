{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from io import BytesIO\n","\n","import pandas as pd\n","import requests\n","import torch\n","import torch.nn as nn\n","from PIL import Image\n","from torch import optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from torchvision.models import resnet18\n","\n","# relative imports only work from current directory without package structure\n","from pytorch_helpers import (\n","    generate_subsets,\n","    generate_train_val_data_split,\n","    plot_regression,\n","    print_param_shapes,\n","    run_regression,\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["front_page_pictures = pd.read_pickle(\"../data-clean/front_page_pictures.pkl\")\n","listings_df = pd.read_pickle(\"../data-clean/listings.pkl\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# drop prices of 0, largest price (outlier) and missing images\n","picture_price_df = (\n","    pd.merge(\n","        front_page_pictures, listings_df[\"price\"], left_index=True, right_index=True\n","    )\n","    .loc[lambda x: (x[\"price\"] > 0) & (x[\"price\"] < 80000)]\n","    .dropna()\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["IMAGE_SIZE = [224, 224]\n","batch_size = 8\n","\n","image_transforms = transforms.Compose(\n","    [transforms.Resize(size=IMAGE_SIZE), transforms.PILToTensor()]\n",")\n","\n","# normalization requires four dimensions, done after unsqueezing\n","# values of channel means and standard deviations from documentation for resnet https://pytorch.org/vision/stable/models.html\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ListingsImages(Dataset):\n","    \"\"\"\n","    Creates PyTorch Dataset from Pandas DataFrame containing (at least) one Column of Picture URLs and one additional Column of corresponding Prices.\n","    The resulting Images are resized and normalized four-dimensional Tensors and serve, together with the returned Price Tensors, as Input to a PyTorch DataLoader object.\n","    \"\"\"\n","\n","    def __init__(self, df, image_transforms=None):\n","        self.x = df[\"listing_url\"]\n","        self.y = torch.tensor(df[\"price\"].values, dtype=torch.float)\n","        self.image_transforms = image_transforms\n","\n","    def __getitem__(self, index):\n","        url = self.x.iloc[index]\n","        response = requests.get(url)\n","        img = Image.open(BytesIO(response.content))\n","        label = self.y[index]\n","\n","        if self.image_transforms is not None:\n","            img_tensor = self.image_transforms(img).to(dtype=torch.float)\n","            img_tensor = normalize(img_tensor)\n","\n","        return img_tensor, label\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_dataset = ListingsImages(picture_price_df, image_transforms)\n","trainset, valset = generate_train_val_data_split(full_dataset)\n","\n","# comment out to train on full dataset\n","trainset, valset = generate_subsets(trainset, valset, subset_size=batch_size)\n","\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","valloader = DataLoader(valset, batch_size=batch_size, shuffle=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = resnet18(pretrained=True).to(device=device)\n","\n","# freeze weights\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# replace last fully connected layer, weights of new layer require gradient computation\n","in_features = model.fc.in_features\n","model.fc = nn.Linear(in_features, 1)\n","\n","print_param_shapes(model)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["params_to_update = [param for param in model.parameters() if param.requires_grad]\n","print(\"Parameters to train:\", sum(param.numel() for param in params_to_update))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lr = 0.01\n","num_epochs = 5\n","# use only parameters with requires_grad = True in optimizer\n","optimizer = optim.Adam(params_to_update, lr=lr)\n","\n","loss_function = nn.MSELoss()\n","train_losses, val_losses, train_maes, val_maes, train_r2s, val_r2s = run_regression(\n","    model,\n","    optimizer,\n","    loss_function,\n","    device,\n","    num_epochs,\n","    trainloader,\n","    valloader,\n","    verbose=True,\n","    save_best=True,\n",")\n","\n","plot_regression(train_losses, val_losses, train_maes, val_maes, train_r2s, val_r2s)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}